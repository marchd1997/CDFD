{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480e6f0a-91b2-454b-8d7f-b1175a8f082d",
   "metadata": {},
   "source": [
    "# Cleaning and grouping Sarafu data\n",
    "Based on code from \"Mattsson, C.E.S., Criscione, T. & Takes, F.W. Circulation of a digital community currency. Sci Rep 13, 5864 (2023). https://doi.org/10.1038/s41598-023-33184-1\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b1dd79a-aab7-49ef-97fc-43fe74ba64c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9974c8-1ec4-47f5-93ea-bd539195a25c",
   "metadata": {},
   "source": [
    "## Directory paths & transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f95eda-fa2e-4fb7-9345-378ee5a62427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define directories\n",
    "projdir = \"\"\n",
    "datadir = \"data_sarafu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31264c21-d1cb-41c2-82db-f51ca513677d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load into pandas\n",
    "raw_fn = os.path.join(datadir,\"sarafu_txns_20200125-20210615.csv\")\n",
    "raw = pd.read_csv(raw_fn).drop(columns=['token_name','token_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f70de6-cbfb-49a9-bb8e-61bcecba48fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_fn = os.path.join(datadir,\"sarafu_users_20210615.csv\")\n",
    "categoricals = ['gender','area_name','area_type','held_roles','business_type']\n",
    "strings = ['start','old_POA_blockchain_address','xDAI_blockchain_address']\n",
    "dtypes = {col:\"category\" for col in categoricals}\n",
    "dtypes.update({col:\"string\" for col in strings})\n",
    "users = pd.read_csv(users_fn,dtype=dtypes,na_filter=False)\n",
    "users = users.drop_duplicates(subset=['xDAI_blockchain_address'],keep='first')\n",
    "users = users.set_index('xDAI_blockchain_address')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891cf90c-29e0-423e-9c98-645af9e87c75",
   "metadata": {},
   "source": [
    "## Initial data cleaning \n",
    "\n",
    "Removing transactions directly between system-run accounts and non-standard transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d93cf25f-769a-46d9-93a7-10048d38cc9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter system run accounts\n",
    "admins = ['0xBDB3Bc887C3b70586BC25D04d89eC802b897fC5F','0xEDA5C9B75Fdb3B9bdAB987A704632280Cf93084F']\n",
    "txns_fn = os.path.join(datadir,\"transactions\",\"sarafu_txns.csv\")\n",
    "txns = raw[~((raw['source'].isin(admins)) & (raw['target'].isin(admins)))].copy()\n",
    "\n",
    "# Filter out the currency management and cash exchange operations\n",
    "txns_std = txns[txns['transfer_subtype']==\"STANDARD\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0071ea3a-f17f-42c0-8403-4b54e58fb224",
   "metadata": {},
   "source": [
    "## Sarafu flow network (agregate network by adding weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08bf4058-3753-4704-999a-ff46fb99110c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Total Sarafu over each link\n",
    "flow_net = txns_std.groupby(by = ['source', 'target'])[[\"weight\"]].sum().reset_index() \n",
    "\n",
    "# Edgelist\n",
    "flow_nx = nx.from_pandas_edgelist(flow_net,edge_attr='weight',create_using=nx.DiGraph)\n",
    "\n",
    "# Node information\n",
    "nx.set_node_attributes(flow_nx, users.to_dict('index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751cefac-34fd-4f16-83c7-7c904fd9872f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Second data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f7ab747-0060-46d8-a70f-ba8a52988dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter system accounts\n",
    "has_admin_role = users['held_roles'].isin(['ADMIN','VENDOR'])\n",
    "has_admin_type = users['business_type'].isin(['system'])\n",
    "reg_users = users.loc[~has_admin_role & ~has_admin_type].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72ae5dd1-9baa-48b6-a44a-b4ca7eef034c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gather corresponding subnetwork\n",
    "flow_reg_nx = nx.DiGraph()\n",
    "for e, e_dict in flow_nx.subgraph(reg_users.index).edges.items():\n",
    "    flow_reg_nx.add_edge(*e,**e_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a53c69-7ce5-4c17-a70d-1d2e258ef754",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e8f5cf4-33ba-47af-a891-8db6312759ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dir\n",
    "networks_fn = os.path.join(datadir,\"networks\")\n",
    "if not os.path.exists(networks_fn):\n",
    "    os.makedirs(networks_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7ee3efc-bf4c-4569-9f1e-e962806173a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write in Pajek format\n",
    "flow_reg_fn = os.path.join(networks_fn,\"sarafu_reg_users.net\")\n",
    "nx.write_pajek(flow_reg_nx, flow_reg_fn, encoding='UTF-8')\n",
    "\n",
    "# clean up the file\n",
    "with open(flow_reg_fn, 'r') as file :\n",
    "    filedata = file.read()\n",
    "filedata = filedata.replace(' 0.0 0.0 ellipse', '') \n",
    "with open(flow_reg_fn, 'w') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7009334d-28ba-4121-a070-89a697c990b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nodes 40655\n",
      " edges 145659\n",
      "weight 293688266.0480015\n"
     ]
    }
   ],
   "source": [
    "print(\" nodes\", flow_reg_nx.number_of_nodes())\n",
    "print(\" edges\", flow_reg_nx.number_of_edges())\n",
    "print(\"weight\", flow_reg_nx.size(weight=\"weight\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405719f6-903e-4f9e-880a-97555d5bbd80",
   "metadata": {},
   "source": [
    "# Monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a6c4fdc-abb7-4c8b-ab71-8db097478ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fd0efb3-6c86-4944-9801-a012dc3acd50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate timestamp\n",
    "txns_std['timestamp'] = pd.to_datetime(txns_std['timeset'],format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "# month\n",
    "txns_std['Month'] = txns_std['timestamp'].dt.strftime(\"%Y-%m\") \n",
    "\n",
    "# Monthly volumes of STANDARD transactions -- February through May (removing incomplete months)\n",
    "feb20 = datetime.strptime(\"2020-02-01 00:00:00.00\",\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "jun21 = datetime.strptime(\"2021-06-01 00:00:00.00\",\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "txns_febmay = txns_std[(txns_std['timestamp']>feb20)&(txns_std['timestamp']<jun21)].copy()\n",
    "txns_febmay[\"Month\"] = txns_febmay[\"Month\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677b211-1597-45cd-b185-d4eb5c63f651",
   "metadata": {},
   "source": [
    "## Monthly agregate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "644d6ab9-0b57-477b-bc31-9089ed93cbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flow_net_febmay = txns_febmay.groupby(by = ['Month','source', 'target'])[[\"weight\"]].sum().reset_index() \n",
    "\n",
    "# Get dictionary of dataframes, one dataframe for each month\n",
    "months = flow_net_febmay.Month.unique()\n",
    "flow_net_febmay_dic = {month : flow_net_febmay[flow_net_febmay.Month == month].drop(columns=['Month']) for month in months}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c729d9ff-e052-4c6d-bb23-901fd24b2b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get dictionary of regular users networks \n",
    "flow_reg_febmay = {}\n",
    "\n",
    "for month, flow  in flow_net_febmay_dic.items(): \n",
    "    G = nx.from_pandas_edgelist(flow,edge_attr='weight',create_using=nx.DiGraph)\n",
    "    nx.set_node_attributes(G, users.to_dict('index'))\n",
    "    G_reg = nx.DiGraph()\n",
    "    for e, e_dict in G.subgraph(reg_users.index).edges.items():\n",
    "        G_reg.add_edge(*e,**e_dict)\n",
    "    flow_reg_febmay[month] = G_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81f833-3feb-4c9e-b36e-b29c28a7e36e",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "236ae40e-11a4-4985-9035-f1586d711c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dir\n",
    "monthly_fn = os.path.join(datadir,\"networks\", \"monthly\")\n",
    "if not os.path.exists(monthly_fn):\n",
    "    os.makedirs(monthly_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bc9c624-b1f2-4016-b2ca-382b3e6045a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write in Pajek format\n",
    "for month, G  in flow_reg_febmay.items():\n",
    "    G_fn = os.path.join(monthly_fn,\"sarafu_reg_\"+month+\".net\")\n",
    "    nx.write_pajek(G, G_fn, encoding='UTF-8')\n",
    "\n",
    "# clean up the files\n",
    "for month, G  in flow_reg_febmay.items():\n",
    "    G_fn = os.path.join(monthly_fn,\"sarafu_reg_\"+month+\".net\")\n",
    "    with open(G_fn, 'r') as file :\n",
    "        filedata = file.read()\n",
    "    filedata = filedata.replace(' 0.0 0.0 ellipse', '') \n",
    "    with open(G_fn, 'w') as file:\n",
    "        file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84ded733-9dc8-4ce6-9f31-d75a9b11cfea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                  6594\n",
       "start                                         2019-11-21 12:53:28.000000\n",
       "final_bal                                               49.9098019725512\n",
       "gender                                                            Female\n",
       "area_name                                                   Misc Nairobi\n",
       "area_type                                                          urban\n",
       "held_roles                                                   BENEFICIARY\n",
       "business_type                                                       food\n",
       "old_POA_blockchain_address    0x25c6018e898395db6ac72eb6d6aa2bc28766e2cf\n",
       "ovol_in                                                      5691.909802\n",
       "ovol_out                                                            83.0\n",
       "otxns_in                                                              34\n",
       "otxns_out                                                              4\n",
       "ounique_in                                                             6\n",
       "ounique_out                                                            1\n",
       "svol_in                                                         678976.0\n",
       "svol_out                                                        684535.0\n",
       "stxns_in                                                            1113\n",
       "stxns_out                                                            152\n",
       "sunique_in                                                           541\n",
       "sunique_out                                                           81\n",
       "Name: 0xa2b55ff5940297F42Ac638d37EC455754eA354cB, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_users.loc[\"0xa2b55ff5940297F42Ac638d37EC455754eA354cB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f0e3c5-3d1f-4cfe-b729-91d3b105fa6d",
   "metadata": {},
   "source": [
    "# Creating communities data (in file 2 supplementary materials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d7256cd-5711-4036-a696-6429866de49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febad315-6ec9-4dc7-8d05-fb0ad48eb6fc",
   "metadata": {},
   "source": [
    "## Infomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd761fc6-4b77-44fa-8952-c887d94a8ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create an 'infomap' folder within the 'analysis' directory, and\n",
    "# run Infomap using the following script, or via the command line:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf590b5a-6f62-407c-b17c-75e7fade3384",
   "metadata": {},
   "source": [
    "#!/bin/bash  \n",
    "\n",
    "DATA='/Users/mattssonc/Documents/Research/Sarafu/Sarafu2021_UKDS'\n",
    "WORKING='/Users/mattssonc/Documents/Research/Sarafu/Exploration'\n",
    "\n",
    "infomap --flow-model rawdir --tree \\\\$DATA/networks/sarafu_reg_users.net \\\\$WORKING/analysis/infomap/ > \\\\$WORKING/analysis/infomap/sarafu_reg_users.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a347a9-f826-40c0-b404-f1d0619efea0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load infomap output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dc55066-07f8-4c0b-8dce-08a7e32e59f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load measures & modules\n",
    "reg_users_mod_fn = os.path.join(datadir,\"infomap\",\"sarafu_reg_users.tree\")\n",
    "reg_users_mod = pd.read_csv(reg_users_mod_fn,names=['module','flow','node','idx'],sep=\" \",skiprows=9) # MARC: change 8 to 9\n",
    "reg_users_mod['node'] = reg_users_mod['node'].apply(lambda x: x.strip('\"'))\n",
    "reg_users_mod['mod_1'] = reg_users_mod['module'].apply(lambda x: ':'.join(x.split(':')[:min(1,len(x))]))\n",
    "reg_users_mod['mod_2'] = reg_users_mod['module'].apply(lambda x: ':'.join(x.split(':')[:min(2,len(x))]))\n",
    "reg_users_mod['mod_3'] = reg_users_mod['module'].apply(lambda x: ':'.join(x.split(':')[:min(3,len(x))]))\n",
    "reg_users_mod['mod_4'] = reg_users_mod['module'].apply(lambda x: ':'.join(x.split(':')[:min(4,len(x))]))\n",
    "reg_users_mod['mod_5'] = reg_users_mod['module'].apply(lambda x: ':'.join(x.split(':')[:min(5,len(x))]))\n",
    "reg_users_mod['mod_6'] = reg_users_mod['module'].apply(lambda x: ':'.join(x.split(':')[:min(6,len(x))]))\n",
    "reg_users_mod['mod_7'] = reg_users_mod['module'].apply(lambda x: ':'.join(x.split(':')[:min(7,len(x))]))\n",
    "reg_users_mod = reg_users_mod.drop(['idx','flow'],axis=1)\n",
    "reg_users_mod = reg_users_mod.set_index('node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d0e4237-b333-4cbc-8152-f082593cf7ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set node attributes\n",
    "reg_users = reg_users_mod.join(reg_users, how='left')\n",
    "# Flow network\n",
    "nx.set_node_attributes(flow_reg_nx, reg_users.to_dict('index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77a29bff-71fe-4341-89fa-a62aad68b76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes 40655\n",
      "users 40655\n"
     ]
    }
   ],
   "source": [
    "# Confirm consistent number of nodes\n",
    "print(\"nodes\",flow_reg_nx.number_of_nodes()) # MARC: we lost 2 nodes, at some point check if can recover\n",
    "print(\"users\",reg_users.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d18b8e02-ad8f-44d2-b4f4-b3b2741ed002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'module': '1:7:3:8',\n",
       " 'mod_1': '1',\n",
       " 'mod_2': '1:7',\n",
       " 'mod_3': '1:7:3',\n",
       " 'mod_4': '1:7:3:8',\n",
       " 'mod_5': '1:7:3:8',\n",
       " 'mod_6': '1:7:3:8',\n",
       " 'mod_7': '1:7:3:8',\n",
       " 'id': 15126,\n",
       " 'start': '2020-04-20 09:00:58.865892',\n",
       " 'final_bal': '3593.46',\n",
       " 'gender': 'Female',\n",
       " 'area_name': 'Mukuru Nairobi',\n",
       " 'area_type': 'urban',\n",
       " 'held_roles': 'BENEFICIARY',\n",
       " 'business_type': 'labour',\n",
       " 'old_POA_blockchain_address': '',\n",
       " 'ovol_in': 4519.86,\n",
       " 'ovol_out': 216.4,\n",
       " 'otxns_in': 25,\n",
       " 'otxns_out': 4,\n",
       " 'ounique_in': 3,\n",
       " 'ounique_out': 1,\n",
       " 'svol_in': 29410.0,\n",
       " 'svol_out': 30120.0,\n",
       " 'stxns_in': 114,\n",
       " 'stxns_out': 95,\n",
       " 'sunique_in': 14,\n",
       " 'sunique_out': 13}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_reg_nx.nodes['0x0831252aE03010CeB7C0fd8032d4bC9aB3B84B80']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36361d-e878-4bc5-bb55-8b5ec02f3a3f",
   "metadata": {},
   "source": [
    " ## Format & save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3103b5f-abe1-407c-82ef-bc0d5b221d7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Networks by top-level and second-level infomap module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "722d8f8d-6534-4df7-a5dd-bd1688f2e276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modules\n",
    "mod_1s = ['1','2','3','4','5']\n",
    "mod_2s = [key for key, value in Counter(dict(flow_reg_nx.nodes(data=\"mod_2\")).values()).items() if value > 100]\n",
    "mod_3s = [key for key, value in Counter(dict(flow_reg_nx.nodes(data=\"mod_3\")).values()).items() if value > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a5076eb7-a4bd-4b26-a19e-8015050e2517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer modules in_weight tot_weight fraction\n",
      "mod_1 5 292913149.2380003 293688266.0480015 0.9973607498166965\n",
      "mod_2 36 283681910.3480001 293688266.0480015 0.9659286500116218\n",
      "mod_3 456 238295271.27400002 293688266.0480015 0.8113884646486085\n"
     ]
    }
   ],
   "source": [
    "# Split the network by module\n",
    "flow_reg_nxs = {}\n",
    "print(\"layer\",\"modules\",\"in_weight\",\"tot_weight\",\"fraction\")\n",
    "for label, modules in [('mod_1',mod_1s),('mod_2',mod_2s),('mod_3',mod_3s)]:\n",
    "    total_weight = 0\n",
    "    flow_reg_nxs[label] = {}\n",
    "    for module in modules:\n",
    "        # Gather the network subgraph\n",
    "        flow_reg_nxs[label][module] = nx.DiGraph()\n",
    "        for e, e_dict in flow_reg_nx.subgraph(reg_users[reg_users[label]==module].index).edges.items():\n",
    "            flow_reg_nxs[label][module].add_edge(*e,**e_dict)\n",
    "        total_weight += flow_reg_nxs[label][module].size(weight=\"weight\")\n",
    "    print(label,len(modules),total_weight,flow_reg_nx.size(weight=\"weight\"),total_weight/flow_reg_nx.size(weight=\"weight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afd3b074-5f22-4ec6-85a1-c99f56f2bba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating dirs\n",
    "modules_fn = os.path.join(datadir,\"networks\",\"modules\")\n",
    "if not os.path.exists(modules_fn):\n",
    "            os.makedirs(modules_fn)\n",
    "\n",
    "for module in ['mod_1', 'mod_2']: \n",
    "    module_fn = os.path.join(modules_fn, module)\n",
    "    if not os.path.exists(module_fn):\n",
    "                os.makedirs(module_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd143edf-34bc-4eb6-9a04-fbc4c99fef53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write in Pajek format \n",
    "for label, modules in [('mod_1',mod_1s),('mod_2',mod_2s)]:\n",
    "    for module in modules:\n",
    "        flow_reg_fn = os.path.join(modules_fn ,label,\"sarafu_reg_users_\"+module.replace(':',\"~\")+\".net\")\n",
    "        nx.write_pajek(flow_reg_nxs[label][module], flow_reg_fn, encoding='UTF-8')\n",
    "\n",
    "# clean up the files     \n",
    "for label, modules in [('mod_1',mod_1s),('mod_2',mod_2s)]:\n",
    "    for module in modules:\n",
    "        flow_reg_fn = os.path.join(modules_fn ,label,\"sarafu_reg_users_\"+module.replace(':',\"~\")+\".net\")\n",
    "        with open(flow_reg_fn, 'r') as file :\n",
    "            filedata = file.read()\n",
    "        filedata = filedata.replace(' 0.0 0.0 ellipse', '')\n",
    "        with open(flow_reg_fn, 'w') as file: # MARC: maybe have to run it a couple of times before works\n",
    "            file.write(filedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b2e2d-0fac-4a3e-b5b6-5ef2392a7e7c",
   "metadata": {},
   "source": [
    "If an error occurs in the previous cell try running twice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
